{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# source: https://www.kaggle.com/nobletp/panda-keras-baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#python3 effnb3.py --cnnpar effnB3 --mfolder effnB3_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensorflow version: 2.2.0\n",
      "no gpus\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import os, argparse\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "import json\n",
    "import skimage.io\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras import Model, Sequential\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.utils import Sequence\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import efficientnet.tfkeras as efn\n",
    "#import albumentations as albu\n",
    "print('tensorflow version:', tf.__version__)\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "        logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "        print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "    except RuntimeError as e:\n",
    "        print(e)\n",
    "else:\n",
    "    print('no gpus')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import panda_bvv_config\n",
    "from panda_bvv_config import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ap = argparse.ArgumentParser()\n",
    "# ap.add_argument('--cnnpar', type=str, help=\"parameters name\", dest = 'cnn_parameters', default = 'effnB3')\n",
    "# ap.add_argument('--mfolder', help=\"folder to save model files\", dest = 'mfolder', default = 'effnB3_model',\\\n",
    "#                 type=str)\n",
    "#                 #(\"--cnn\", type=str, help=\"training cnn name\", dest = 'train_cnn')\n",
    "# args = vars(ap.parse_args())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FOR TRAIN:\n",
    "# cnnet = args[\"cnn_parameters\"]\n",
    "# model_save_folder = args[\"mfolder\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FOR TEST:\n",
    "cnnet = 'effnB3_test'\n",
    "model_save_folder = 'effnB3test'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn_rate = 3e-3\n",
    "inp_patience = 14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_weights = panda_bvv_config.class_weights\n",
    "input_parameters = panda_bvv_config.train_dict.get(cnnet)\n",
    "\n",
    "image_sizey = input_parameters.get('image_sizey')\n",
    "image_sizex = input_parameters.get('image_sizex')\n",
    "num_epochs = input_parameters.get('num_epochs')\n",
    "BS = input_parameters.get('BS')\n",
    "s_per_epoch = input_parameters.get('s_per_epoch')\n",
    "val_steps = input_parameters.get('val_steps')\n",
    "model_name = input_parameters.get('model_name')\n",
    "checkpoint_name = input_parameters.get('checkpoint_name')\n",
    "weights_file = input_parameters.get('weights_file')\n",
    "file_for_struct = input_parameters.get('file_for_struct')\n",
    "file_for_weights = input_parameters.get('file_for_weights')\n",
    "history_file = input_parameters.get('history_file')\n",
    "save_plot_file = input_parameters.get('save_plot_file')\n",
    "\n",
    "input_shape_ =(image_sizey, image_sizex , 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNN input parameters: {'image_sizey': 320, 'image_sizex': 320, 'num_epochs': 2, 'num_earlyStop': 2, 'num_reduceOnPlateu': 8, 'BS': 10, 's_per_epoch': 20, 'val_steps': 8, 'model_name': 'model_panda.h5', 'checkpoint_name': 'model_effnB3_panda_check', 'weights_file': 'efficientnet-b3_weights_tf_dim_ordering_tf_kernels_autoaugment_notop.h5', 'file_for_struct': 'model_effnB3_panda_struct.json', 'file_for_weights': 'model_effnB3_panda_weights.json', 'history_file': 'history_effnB3.json', 'save_plot_file': 'plot_edu_effnb3.png'}\n"
     ]
    }
   ],
   "source": [
    "print('CNN input parameters: {}'.format(input_parameters))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_model_save_folder_path = os.path.join(note_path, model_save_folder)\n",
    "if not os.path.exists(full_model_save_folder_path):\n",
    "    print(\"[INFO] 'creating {}' directory\".format(model_save_folder))\n",
    "    os.makedirs(full_model_save_folder_path)\n",
    "model_name = os.path.join(full_model_save_folder_path, model_name)\n",
    "checkpoint_name = os.path.join(full_model_save_folder_path, checkpoint_name)\n",
    "\n",
    "weights_file = os.path.join(note_path, weights_file) #!:not the same path\n",
    "\n",
    "file_for_struct = os.path.join(full_model_save_folder_path, file_for_struct)\n",
    "file_for_weights = os.path.join(full_model_save_folder_path, file_for_weights)\n",
    "history_file = os.path.join(full_model_save_folder_path, history_file)\n",
    "save_plot_file = os.path.join(full_model_save_folder_path, save_plot_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "bottleneck = efn.EfficientNetB3(\n",
    "    input_shape=input_shape_,\n",
    "    weights= weights_file,\n",
    "    include_top=False, \n",
    "    pooling='avg'\n",
    ")\n",
    "bottleneck = Model(inputs=bottleneck.inputs, outputs=bottleneck.layers[-2].output)\n",
    "model = Sequential()\n",
    "model.add(bottleneck)\n",
    "model.add(GlobalAveragePooling2D())\n",
    "model.add(Flatten())\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(.25))\n",
    "model.add(Dense(512, activation='elu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(.25))\n",
    "model.add(Dense(6, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "model (Model)                (None, 10, 10, 1536)      10783528  \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d (Gl (None, 1536)              0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 1536)              0         \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 1536)              6144      \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 1536)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 512)               786944    \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 512)               2048      \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 6)                 3078      \n",
      "=================================================================\n",
      "Total params: 11,581,742\n",
      "Trainable params: 11,490,350\n",
      "Non-trainable params: 91,392\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_generator = ImageDataGenerator(rescale=1/255.0,\n",
    "                                    rotation_range=20,\n",
    "                                    zoom_range=0.05,\n",
    "                                    width_shift_range=0.1,\n",
    "                                    height_shift_range=0.1,\n",
    "                                    #shear_range=0.05,\n",
    "                                    horizontal_flip=True,\n",
    "                                    vertical_flip=True,\n",
    "                                    #fill_mode=\"nearest\"\n",
    "                                    )\n",
    "\n",
    "val_generator = ImageDataGenerator(rescale=1/255.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1201 images belonging to 6 classes.\n"
     ]
    }
   ],
   "source": [
    "train_datagen = train_generator.flow_from_directory(\n",
    "        train_cnn,\n",
    "        target_size=(image_sizey, image_sizex),\n",
    "        color_mode=\"rgb\",\n",
    "        batch_size= BS,\n",
    "        shuffle=True,\n",
    "        class_mode='categorical')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1201 images belonging to 6 classes.\n"
     ]
    }
   ],
   "source": [
    "val_datagen = val_generator.flow_from_directory(\n",
    "        valid_cnn,\n",
    "        target_size=(image_sizey, image_sizex),\n",
    "        color_mode=\"rgb\",\n",
    "        batch_size = BS,\n",
    "        shuffle=False,\n",
    "        class_mode='categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks_list = [\n",
    "        EarlyStopping(\n",
    "        # Stop training when `val_loss` is no longer improving\n",
    "        monitor='val_loss',\n",
    "        mode = 'min',\n",
    "        min_delta=1e-2,\n",
    "        patience=inp_patience,\n",
    "        verbose=1,\n",
    "        restore_best_weights = True\n",
    "        ),\n",
    "        \n",
    "        ModelCheckpoint(\n",
    "        filepath= checkpoint_name +\".{epoch:02d}.h5\",\n",
    "        monitor='val_loss',\n",
    "        mode = 'auto',\n",
    "        save_weights_only = False,\n",
    "        save_freq = 'epoch',\n",
    "        save_best_only=False\n",
    "        ),\n",
    "    \n",
    "        ReduceLROnPlateau(\n",
    "        monitor='val_loss',\n",
    "        factor=.1,\n",
    "        patience=5,\n",
    "        verbose=1,\n",
    "        min_lr=1e-7\n",
    "        )\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    loss  = tf.keras.losses.CategoricalCrossentropy(label_smoothing = 0.15),\n",
    "    #loss='categorical_crossentropy',\n",
    "    optimizer=Adam(lr=learn_rate),\n",
    "    metrics=['categorical_accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(\n",
    "    train_datagen,\n",
    "    steps_per_epoch=s_per_epoch,\n",
    "    validation_data=val_datagen,\n",
    "    validation_steps=val_steps,\n",
    "    class_weight=class_weights,\n",
    "    callbacks=callbacks_list,\n",
    "    epochs=num_epochs,\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_to_save = {}\n",
    "for k, v in history.history.items():\n",
    "    dict_to_save.update({k: [np.format_float_positional(x) for x in history.history[k]]})\n",
    "with open(history_file, 'w') as file:\n",
    "    json.dump(dict_to_save, file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use(\"ggplot\")\n",
    "plt.figure()\n",
    "\n",
    "plt.plot(np.arange(0, num_epochs), history.history['loss'], label='loss')\n",
    "plt.plot(np.arange(0, num_epochs), history.history['val_loss'], label='val_loss')\n",
    "plt.plot(np.arange(0, num_epochs),history.history['categorical_accuracy'], label='cat. accuracy')\n",
    "plt.plot(np.arange(0, num_epochs),history.history['val_categorical_accuracy'], label='val_accuracy')\n",
    "plt.title(\"Training Loss and Accuracy on Dataset\")\n",
    "plt.xlabel(\"Epoch #\")\n",
    "plt.ylabel(\"Loss/Accuracy\")\n",
    "plt.legend(loc=\"lower left\")\n",
    "plt.savefig(save_plot_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(model_name)\n",
    "model.save_weights(file_for_weights, save_format=\"h5\")\n",
    "json_config = model.to_json()\n",
    "with open(file_for_struct, 'w') as f:\n",
    "    json.dump(json_config, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "module_name = 'effnB3'\n",
    "\n",
    "os.system('jupyter nbconvert --to python ' + module_name + '.ipynb')\n",
    "with open(module_name + '.py', 'r') as f:\n",
    "    lines = f.readlines()\n",
    "with open(module_name + '.py', 'w') as f:\n",
    "    for line in lines:\n",
    "        if 'nbconvert --to python' in line:\n",
    "            break\n",
    "        else:\n",
    "            f.write(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow2",
   "language": "python",
   "name": "tf2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
